Privacy principles: search, learning and artificial intelligenceOur mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our privacy policy, security documentation and SPARC and the Slack Terms. Machine learning (ML) and artificial intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. We do not develop LLMs or other generative models using customer data. To develop non-generative AI/ML models for features such as emoji and channel recommendations, our systems analyse Customer Data (e. g. messages, content and files) submitted to Slack as well as Other Information (including usage information) as defined in our privacy policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles:Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data. We have technical controls in place to prevent access. When developing AI/ML models or otherwise analysing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our security white paper for more info on these controls that protect the confidentiality and security of Customer Data. We offer customers a choice around these practices. If you want to exclude your Customer Data from helping to train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack. com with your workspace/org URL and the subject line â€˜Slack global model opt-out requestâ€™. We will process your request and respond once the opt-out has been completed. Customer Data and Other InformationHow Slack may use Customer Data (e. g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: Channel recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel that we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our engineering blog to learn more. Search results: Our search machine learning models help users to find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information such as the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. Autocomplete: Slack might make suggestions to complete search queries or other text â€“ for example autocompleting the phrase â€˜Customer Supportâ€™ after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. Emoji suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji and the frequency of use of the emoji in the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest that users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an external model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace. These types of thoughtful personalisations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations as described in our customer agreements and privacy policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors. Generative AI Generative AI is a newer category of AI systems that can generate content such as text in response to prompts that a user enters. This AI category includes large language models (LLMs). Slack uses generative AI in its Slack AI product offering, leveraging third-party LLMs. Customers purchase Slack AI as an add-on, and the generative AI functionality is not included in the standard Slack offering. No Customer Data is used to train third-party LLM models. Slack does not train LLMs or other generative models on Customer Data, or share Customer Data with any LLM providers. Learn more about how we built Slack AI to be secure and private. Slack AI uses off-the-shelf LLMs where the models are not updated by and donâ€™t in other ways retain Customer Data after a request to them. Additionally, because Slack AI hosts these models on its own AWS infrastructure, Customer Data never leaves Slackâ€™s trust boundary, and the providers of the LLM never have any access to the Customer Data. Slack AI Generative Search AnswersSlack AIâ€™s Search functionality pulls from the following sources: Slack features (canvases, huddles canvas notes, clip transcripts and text snippets); files uploaded to Slack (PDFs, emails, docx, pptx and Keynote); linked documents from Google Drive (Docs, Slides); Sharepoint/OnDrive (Word, Powerpoint) and file storage partner apps like Box (when installed). The user must be authenticated via the integration with Slack to access these files. Admin settings are available to disable all file results or disable sourcing from externally hosted files. Learn more in the Help Centre or admin guide deck. Privacy principles: search, learning and artificial intelligenceOur mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our privacy policy, security documentation and SPARC and the Slack Terms. Machine learning (ML) and artificial intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. We do not develop LLMs or other generative models using customer data. To develop non-generative AI/ML models for features such as emoji and channel recommendations, our systems analyse Customer Data (e. g. messages, content and files) submitted to Slack as well as Other Information (including usage information) as defined in our privacy policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles:Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data. We have technical controls in place to prevent access. When developing AI/ML models or otherwise analysing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our security white paper for more info on these controls that protect the confidentiality and security of Customer Data. We offer customers a choice around these practices. If you want to exclude your Customer Data from helping to train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack. com with your workspace/org URL and the subject line â€˜Slack global model opt-out requestâ€™. We will process your request and respond once the opt-out has been completed. Customer Data and Other InformationHow Slack may use Customer Data (e. g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: Channel recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel that we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our engineering blog to learn more. Search results: Our search machine learning models help users to find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information such as the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. Autocomplete: Slack might make suggestions to complete search queries or other text â€“ for example autocompleting the phrase â€˜Customer Supportâ€™ after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. Emoji suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji and the frequency of use of the emoji in the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest that users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an external model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace. These types of thoughtful personalisations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations as described in our customer agreements and privacy policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors. Generative AI Generative AI is a newer category of AI systems that can generate content such as text in response to prompts that a user enters. This AI category includes large language models (LLMs). Slack uses generative AI in its Slack AI product offering, leveraging third-party LLMs. Customers purchase Slack AI as an add-on, and the generative AI functionality is not included in the standard Slack offering. No Customer Data is used to train third-party LLM models. Slack does not train LLMs or other generative models on Customer Data, or share Customer Data with any LLM providers. Learn more about how we built Slack AI to be secure and private. Slack AI uses off-the-shelf LLMs where the models are not updated by and donâ€™t in other ways retain Customer Data after a request to them. Additionally, because Slack AI hosts these models on its own AWS infrastructure, Customer Data never leaves Slackâ€™s trust boundary, and the providers of the LLM never have any access to the Customer Data. Slack AI Generative Search AnswersSlack AIâ€™s Search functionality pulls from the following sources: Slack features (canvases, huddles canvas notes, clip transcripts and text snippets); files uploaded to Slack (PDFs, emails, docx, pptx and Keynote); linked documents from Google Drive (Docs, Slides); Sharepoint/OnDrive (Word, Powerpoint) and file storage partner apps like Box (when installed). The user must be authenticated via the integration with Slack to access these files. Admin settings are available to disable all file results or disable sourcing from externally hosted files. Learn more in the Help Centre or admin guide deck. Privacy principles: search, learning and artificial intelligenceOur mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our privacy policy, security documentation and SPARC and the Slack Terms. Machine learning (ML) and artificial intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. We do not develop LLMs or other generative models using customer data. To develop non-generative AI/ML models for features such as emoji and channel recommendations, our systems analyse Customer Data (e. g. messages, content and files) submitted to Slack as well as Other Information (including usage information) as defined in our privacy policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles:Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data. We have technical controls in place to prevent access. When developing AI/ML models or otherwise analysing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our security white paper for more info on these controls that protect the confidentiality and security of Customer Data. We offer customers a choice around these practices. If you want to exclude your Customer Data from helping to train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack. com with your workspace/org URL and the subject line â€˜Slack global model opt-out requestâ€™. We will process your request and respond once the opt-out has been completed. Customer Data and Other InformationHow Slack may use Customer Data (e. g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: Channel recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel that we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our engineering blog to learn more. Search results: Our search machine learning models help users to find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information such as the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. Autocomplete: Slack might make suggestions to complete search queries or other text â€“ for example autocompleting the phrase â€˜Customer Supportâ€™ after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. Emoji suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji and the frequency of use of the emoji in the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest that users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an external model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace. These types of thoughtful personalisations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations as described in our customer agreements and privacy policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors. Generative AI Generative AI is a newer category of AI systems that can generate content such as text in response to prompts that a user enters. This AI category includes large language models (LLMs). Slack uses generative AI in its Slack AI product offering, leveraging third-party LLMs. Customers purchase Slack AI as an add-on, and the generative AI functionality is not included in the standard Slack offering. No Customer Data is used to train third-party LLM models. Slack does not train LLMs or other generative models on Customer Data, or share Customer Data with any LLM providers. Learn more about how we built Slack AI to be secure and private. Slack AI uses off-the-shelf LLMs where the models are not updated by and donâ€™t in other ways retain Customer Data after a request to them. Additionally, because Slack AI hosts these models on its own AWS infrastructure, Customer Data never leaves Slackâ€™s trust boundary, and the providers of the LLM never have any access to the Customer Data. Slack AI Generative Search AnswersSlack AIâ€™s Search functionality pulls from the following sources: Slack features (canvases, huddles canvas notes, clip transcripts and text snippets); files uploaded to Slack (PDFs, emails, docx, pptx and Keynote); linked documents from Google Drive (Docs, Slides); Sharepoint/OnDrive (Word, Powerpoint) and file storage partner apps like Box (when installed). The user must be authenticated via the integration with Slack to access these files. Admin settings are available to disable all file results or disable sourcing from externally hosted files. Learn more in the Help Centre or admin guide deck. Privacy principles: search, learning and artificial intelligenceOur mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our privacy policy, security documentation and SPARC and the Slack Terms. Machine learning (ML) and artificial intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. We do not develop LLMs or other generative models using customer data. To develop non-generative AI/ML models for features such as emoji and channel recommendations, our systems analyse Customer Data (e. g. messages, content and files) submitted to Slack as well as Other Information (including usage information) as defined in our privacy policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles:Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data. We have technical controls in place to prevent access. When developing AI/ML models or otherwise analysing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our security white paper for more info on these controls that protect the confidentiality and security of Customer Data. We offer customers a choice around these practices. If you want to exclude your Customer Data from helping to train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack. com with your workspace/org URL and the subject line â€˜Slack global model opt-out requestâ€™. We will process your request and respond once the opt-out has been completed. Customer Data and Other InformationHow Slack may use Customer Data (e. g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: Channel recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel that we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our engineering blog to learn more. Search results: Our search machine learning models help users to find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information such as the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. Autocomplete: Slack might make suggestions to complete search queries or other text â€“ for example autocompleting the phrase â€˜Customer Supportâ€™ after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. Emoji suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji and the frequency of use of the emoji in the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest that users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an external model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace. These types of thoughtful personalisations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations as described in our customer agreements and privacy policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors. Generative AI Generative AI is a newer category of AI systems that can generate content such as text in response to prompts that a user enters. This AI category includes large language models (LLMs). Slack uses generative AI in its Slack AI product offering, leveraging third-party LLMs. Customers purchase Slack AI as an add-on, and the generative AI functionality is not included in the standard Slack offering. No Customer Data is used to train third-party LLM models. Slack does not train LLMs or other generative models on Customer Data, or share Customer Data with any LLM providers. Learn more about how we built Slack AI to be secure and private. Slack AI uses off-the-shelf LLMs where the models are not updated by and donâ€™t in other ways retain Customer Data after a request to them. Additionally, because Slack AI hosts these models on its own AWS infrastructure, Customer Data never leaves Slackâ€™s trust boundary, and the providers of the LLM never have any access to the Customer Data. Slack AI Generative Search AnswersSlack AIâ€™s Search functionality pulls from the following sources: Slack features (canvases, huddles canvas notes, clip transcripts and text snippets); files uploaded to Slack (PDFs, emails, docx, pptx and Keynote); linked documents from Google Drive (Docs, Slides); Sharepoint/OnDrive (Word, Powerpoint) and file storage partner apps like Box (when installed). The user must be authenticated via the integration with Slack to access these files. Admin settings are available to disable all file results or disable sourcing from externally hosted files. Learn more in the Help Centre or admin guide deck. Privacy principles: search, learning and artificial intelligence Our mission is to build a product that makes work life simpler, more pleasant and more productive. Our guiding principle as we build this product is that the privacy and security of Customer Data is sacrosanct, as detailed in our privacy policy, security documentation and SPARC and the Slack Terms. Machine learning (ML) and artificial intelligence (AI) are useful tools that we use in limited ways to enhance our product mission. We do not develop LLMs or other generative models using customer data. To develop non-generative AI/ML models for features such as emoji and channel recommendations, our systems analyse Customer Data (e. g. messages, content and files) submitted to Slack as well as Other Information (including usage information) as defined in our privacy policy and in your customer agreement. To ensure the privacy and security of Customer Data in this particular context, we have a few guiding principles: Contact us to opt out. If you want to exclude your Customer Data from Slack global models, you can opt out. To opt out, please have your org, workspace owners or primary owner contact our Customer Experience team at feedback@slack. com with your workspace/org URL and the subject line â€˜Slack global model opt-out requestâ€™. We will process your request and respond once the opt-out has been completed. Customer Data and Other Information How Slack may use Customer Data (e. g. messages, content, files) and Other Information to update our services Working from the above principles, here are a few examples of improvements and privacy protective techniques that our product and analytics teams may use to develop, update and improve Slack: These types of thoughtful personalisations and improvements are only possible if we study and understand how our users interact with Slack. Slack takes privacy seriously and our confidentiality obligations as described in our customer agreements and privacy policy apply in each of these scenarios. Customers own their own Customer Data. Slack aggregates and disassociates Customer Data such that Slackâ€™s use of Customer Data to update the Services will never identify any of our customers or individuals as the source of any of these improvements to any third party, other than to Slackâ€™s affiliates or sub-processors. Generative AI Generative AI is a newer category of AI systems that can generate content such as text in response to prompts that a user enters. This AI category includes large language models (LLMs). Slack uses generative AI in its Slack AI product offering, leveraging third-party LLMs. Customers purchase Slack AI as an add-on, and the generative AI functionality is not included in the standard Slack offering. No Customer Data is used to train third-party LLM models. Slack does not train LLMs or other generative models on Customer Data, or share Customer Data with any LLM providers. Learn more about how we built Slack AI to be secure and private. Slack AI uses off-the-shelf LLMs where the models are not updated by and donâ€™t in other ways retain Customer Data after a request to them. Additionally, because Slack AI hosts these models on its own AWS infrastructure, Customer Data never leaves Slackâ€™s trust boundary, and the providers of the LLM never have any access to the Customer Data. Slack AI Generative Search Answers Slack AIâ€™s Search functionality pulls from the following sources: Slack features (canvases, huddles canvas notes, clip transcripts and text snippets); files uploaded to Slack (PDFs, emails, docx, pptx and Keynote); linked documents from Google Drive (Docs, Slides); Sharepoint/OnDrive (Word, Powerpoint) and file storage partner apps like Box (when installed). The user must be authenticated via the integration with Slack to access these files. Admin settings are available to disable all file results or disable sourcing from externally hosted files. Learn more in the Help Centre or admin guide deck. Esc Try Slack with your team for freeGet started Try Slack with your team for freeGet started Try Slack with your team for free â€¢ Data will not leak across workspaces. For any model that will be used broadly across all of our customers, we do not build or train these models in such a way that they could learn, memorise, or be able to reproduce some part of Customer Data. â€¢ We have technical controls in place to prevent access. When developing AI/ML models or otherwise analysing Customer Data, Slack canâ€™t access the underlying content. We have various technical measures preventing this from occurring. Please read our security white paper for more info on these controls that protect the confidentiality and security of Customer Data. â€¢ We offer customers a choice around these practices. If you want to exclude your Customer Data from helping to train Slack global models, you can opt out. If you opt out, Customer Data on your workspace will only be used to improve the experience on your own workspace and you will still enjoy all of the benefits of our globally trained AI/ML models without contributing to the underlying models. â€¢ Channel recommendations: We may use insights to recommend that a user joins a new public channel in their company. We make these suggestions based on channel membership, activity and topic overlaps. Our model learns from previous suggestions and whether or not a user joins the channel that we recommend. We protect privacy while doing so by separating our model from Customer Data. We use external models (not trained on Slack messages) to evaluate topic similarity, outputting numerical scores. Our global model only makes recommendations based on these numerical scores and non-Customer Data. For more technical details, please visit our engineering blog to learn more. â€¢ Search results: Our search machine learning models help users to find what they're seeking by identifying the right results for a particular query. We do this based on historical search results and previous engagements without learning from the underlying text of the search query, result or proxy. Simply put, our model can't reconstruct the search query or result. Instead, it learns from team-specific, contextual information such as the number of times a message has been clicked in a search or an overlap in the number of words in the query and recommended message. â€¢ Autocomplete: Slack might make suggestions to complete search queries or other text â€“ for example autocompleting the phrase â€˜Customer Supportâ€™ after a user types the first several letters of this phrase. These suggestions are local and sourced from common public message phrases in the userâ€™s workspace. Our algorithm that picks from potential suggestions is trained globally on previously suggested and accepted completions. We protect data privacy by using rules to score the similarity between the typed text and suggestion in various ways, including only using the numerical scores and counts of past interactions in the algorithm. â€¢ Emoji suggestion: Slack might suggest emoji reactions to messages using the content and sentiment of the message, the historic usage of the emoji and the frequency of use of the emoji in the team in various contexts. For instance, if ðŸŽ‰ is a common reaction to celebratory messages in a particular channel, we will suggest that users react to new, similarly positive messages with ðŸŽ‰. To do this while protecting Customer Data, we might use an external model (not trained on Slack messages) to classify the sentiment of the message. Our model would then suggest an emoji only considering the frequency with which a particular emoji has been associated with messages of that sentiment in that workspace.