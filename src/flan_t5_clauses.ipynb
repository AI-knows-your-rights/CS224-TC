{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e13e2f7",
   "metadata": {},
   "source": [
    "We can use flan t5 to generate clauses of the terms and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c49dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATADIR = 'data_all_202503130545112'\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), '../', DATADIR)\n",
    "\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    \"\"\"\n",
    "    Load text from a file and return the content as a string.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the text file.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        IOError: If there is an error reading the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} was not found.\")\n",
    "        raise\n",
    "    except IOError as e:\n",
    "        print(f\"Error: An error occurred while reading the file at {file_path}.\")\n",
    "        raise e\n",
    "\n",
    "def get_tc_files(website_name):#+\n",
    "    \"\"\"#+\n",
    "    Retrieve the text content of terms and conditions files for a given website.#+\n",
    "#+\n",
    "    Args:#+\n",
    "        website_name (str): The name of the website whose terms and conditions files are to be retrieved.#+\n",
    "#+\n",
    "    Returns:#+\n",
    "        list of str: A list containing the text content of each terms and conditions file.#+\n",
    "#+\n",
    "    Raises:#+\n",
    "        FileNotFoundError: If the documents directory or any TC_ file does not exist.#+\n",
    "        IOError: If there is an error reading any of the TC_ files.#+\n",
    "    \"\"\"#+\n",
    "    documents_path = os.path.join(data_path, website_name, 'documents')#+\n",
    "    tc_files = [os.path.join(documents_path, file) for file in os.listdir(documents_path) if file.startswith('TC_') and file.endswith('.txt')]#+\n",
    "    tc_texts = [load_text_file(tc_file) for tc_file in tc_files]#+\n",
    "    return tc_texts#+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ece7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1dd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_name = '23andMe'\n",
    "sample_TC = get_tc_files(website_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17cc8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23andMe has 4 TC files.\n",
      "Text 1 length: 16905 characters\n",
      "Text 2 length: 24197 characters\n",
      "Text 3 length: 60862 characters\n",
      "Text 4 length: 38579 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'{website_name} has {len(sample_TC)} TC files.')\n",
    "\n",
    "for i, text in enumerate(sample_TC):\n",
    "    print(f\"Text {i+1} length: {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9becde7a-c6d7-4973-bae5-9ea201299c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d580c55d2d044ab08623ac700ad38f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d7ca2f69d4477ebebe22b71dcad883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35cb16215764a77891461233071f6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4611c86f143f454d858dbe7eddcfdd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c5690a76e24a668fac4ca2864b75e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdf766ad2f2427282d9a06fd3080085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92828728a1124055ae7011367abd813a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e16637a43f49eb86fdf2c478914bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e920fd7664a34a0eb5628a54fcd659c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/9.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c6ef34220446a49681107646eaa15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d967bb20efae4aecadff30226fa9f403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9f6f9622c40289a1f72fd152bbde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/6.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa391ef72404313bf8f5e93862e4366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b355d8b54f5f4a4a803b78592c0148de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the llama model from hugging face\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# model Card for FLAN-T5 XXL\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xxl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b7b4b",
   "metadata": {},
   "source": [
    "# Tokenize the sample TC and show the tokenized length\n",
    "tokenized_sample_TC = [tokenizer(text, return_tensors='pt') for text in sample_TC]\n",
    "\n",
    "for i, tokenized_text in enumerate(tokenized_sample_TC):\n",
    "    print(f\"Tokenized Text {i+1} length: {tokenized_text['input_ids'].size(1)} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"LeeRuben/cppe5_use_data_finetuning\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"LeeRuben/cppe5_use_data_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1\", trust_remote_code=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc_ranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
